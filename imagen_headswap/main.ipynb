{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bd38515",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import base64\n",
    "import requests\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "os.makedirs(\"_output\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5dfab0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "FORGE_INSTANCE_URL = \"http://127.0.0.1:1234\" # \"http://127.0.0.1:1234\" / \"https://*-1234.proxy.runpod.net\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cc0cc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upscale_image(img_inp_path, img_out_path):\n",
    "\n",
    "    with open(img_inp_path, \"rb\") as f_img_inp:\n",
    "        img_inp_base64 = base64.b64encode(f_img_inp.read()).decode('utf-8')\n",
    "    # img_h, img_w, _ = cv2.imread(img_inp_path).shape\n",
    "\n",
    "    payload = {\n",
    "        \"resize_mode\": 0,                  # Sets the resize mode: 0 to upscale by upscaling_resize amount, 1 to upscale up to upscaling_resize_h x upscaling_resize_w.\n",
    "        \"show_extras_results\": False,      # Should the backend return the generated image?\n",
    "        \"gfpgan_visibility\": 0.35,         # Sets the visibility of GFPGAN, values should be between 0 and 1.\n",
    "        \"codeformer_visibility\": 0,        # Sets the visibility of CodeFormer, values should be between 0 and 1.\n",
    "        \"codeformer_weight\": 0,            # Sets the weight of CodeFormer, values should be between 0 and 1.\n",
    "        \"upscaling_resize\": 4,             # By how much to upscale the image, only used when resize_mode=0.\n",
    "        \"upscaling_resize_w\": 512,         # Target width for the upscaler to hit. Only used when resize_mode=1.\n",
    "        \"upscaling_resize_h\": 512,         # Target height for the upscaler to hit. Only used when resize_mode=1.\n",
    "        \"upscaling_crop\": True,            # Should the upscaler crop the image to fit in the chosen size?\n",
    "        \"upscaler_1\": \"R-ESRGAN 4x+\",      # The name of the main upscaler to use\n",
    "        \"upscaler_2\": \"None\",              # The name of the secondary upscaler to use\n",
    "        \"extras_upscaler_2_visibility\": 0, # Sets the visibility of secondary upscaler, values should be between 0 and 1.\n",
    "        \"upscale_first\": False,            # Should the upscaler run before restoring faces?\n",
    "        \"image\": img_inp_base64            # Image to work on, must be a Base64 string containing the image's data.\n",
    "    }\n",
    "\n",
    "    def request_forge_instance(payload, img_out_path):\n",
    "        try:\n",
    "            with requests.post(url=FORGE_INSTANCE_URL+\"/sdapi/v1/extra-single-image\", json=payload) as req:\n",
    "                with open(img_out_path, \"wb\") as f:\n",
    "                    f.write(base64.b64decode(req.json()[\"image\"]))\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error: {e}\")\n",
    "            print(f\"⚠️ req.json(): {req.json()}\")\n",
    "    request_forge_instance(payload, img_out_path)\n",
    "\n",
    "def resize_image(img_inp_path, img_out_path, new_width=1080):\n",
    "    img = cv2.imread(img_inp_path)\n",
    "    h, w, _ = img.shape\n",
    "    new_height = int(h * new_width / w)\n",
    "    img_resized = cv2.resize(img, (new_width, new_height), interpolation=cv2.INTER_LANCZOS4)\n",
    "    cv2.imwrite(img_out_path, img_resized)\n",
    "\n",
    "def create_facemask(img_inp_path, img_keypoints_path, img_mask_path, expand_scale_factor=1.2):\n",
    "    def get_ls_keypoints(img_inp_path, img_out_path, expand_scale_factor):\n",
    "        def expand_polygon(ls_keypoints, expand_scale_factor):\n",
    "            points = np.array(ls_keypoints, dtype=np.float32)                      # Convert keypoints to a NumPy array\n",
    "            centroid = np.mean(points, axis=0)                                     # Calculate the centroid of the polygon\n",
    "            expanded_points = centroid + (points - centroid) * expand_scale_factor # Translate points to origin (subtract centroid), scale, and translate back\n",
    "            expanded_points = expanded_points.astype(np.int32)                     # Convert back to integer coordinates for OpenCV\n",
    "            return expanded_points.tolist()\n",
    "        # Read image\n",
    "        img_raw = cv2.imread(img_inp_path)\n",
    "        img_rgb = cv2.cvtColor(img_raw, cv2.COLOR_BGR2RGB)\n",
    "        h, w, _ = img_raw.shape\n",
    "        # MediaPipe: Extract face landmarks\n",
    "        with mp.solutions.face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, refine_landmarks=True, min_detection_confidence=0.2) as face_mesh:\n",
    "            mp_res = face_mesh.process(img_rgb)\n",
    "            if mp_res.multi_face_landmarks:\n",
    "                for facelandmarks in mp_res.multi_face_landmarks:\n",
    "                    # Landmark indices\n",
    "                    ls_indices = [10,338,297,332,284,251,389,356,454,323,361,288,397,365,379,378,400,377,152,148,176,149,150,136,172,58,132,93,234,127,162,21,54,103,67,109]\n",
    "                    # Get coordinates\n",
    "                    ls_keypoints = []\n",
    "                    for idx in ls_indices:\n",
    "                        ls_keypoints.append(\n",
    "                            (int(facelandmarks.landmark[idx].x * w), int(facelandmarks.landmark[idx].y * h)) # 1 keypoint (x,y)\n",
    "                        )\n",
    "                    # Expand polygon\n",
    "                    ls_keypoints_expanded = expand_polygon(ls_keypoints, expand_scale_factor)\n",
    "                    # Draw points\n",
    "                    DRAW_THICKNESS = 18\n",
    "                    cv2.polylines(img_raw, [np.array(ls_keypoints, dtype=np.int32)], isClosed=True, color=(0, 0, 255), thickness=DRAW_THICKNESS)\n",
    "                    cv2.polylines(img_raw, [np.array(ls_keypoints_expanded, dtype=np.int32)], isClosed=True, color=(0, 255, 0), thickness=DRAW_THICKNESS)\n",
    "                    for keypoint in ls_keypoints:\n",
    "                        cv2.circle(img_raw, keypoint, DRAW_THICKNESS, (0, 255, 0), -1)\n",
    "                    cv2.imwrite(img_out_path, img_raw)\n",
    "                    # Return\n",
    "                    return ls_keypoints_expanded\n",
    "        raise ValueError(\"⚠️ No faces detected\")\n",
    "    \n",
    "    ls_keypoints = get_ls_keypoints(img_inp_path, img_keypoints_path, expand_scale_factor)\n",
    "    h, w, _ = cv2.imread(img_inp_path).shape\n",
    "\n",
    "    # Convert to numpy array (required format for OpenCV fillPoly)\n",
    "    ls_keypoints = np.array(ls_keypoints, np.int32)\n",
    "    ls_keypoints = ls_keypoints.reshape((-1, 1, 2)) # shape (n,1,2)\n",
    "    # Create a blank black image (size depends on your image)\n",
    "    img_mask = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "    # Fill the polygon with white\n",
    "    cv2.fillPoly(img_mask, [ls_keypoints], (255, 255, 255))\n",
    "    cv2.imwrite(img_mask_path, img_mask)\n",
    "\n",
    "def inpaint_image(img_inp_path, img_mask_path, img_out_path, sd_params):\n",
    "\n",
    "    with open(img_inp_path, \"rb\") as f_img_inp, open(img_mask_path, \"rb\") as f_img_msk:\n",
    "        img_inp_base64 = base64.b64encode(f_img_inp.read()).decode('utf-8')\n",
    "        img_msk_base64 = base64.b64encode(f_img_msk.read()).decode('utf-8')\n",
    "    img_h, img_w, _ = cv2.imread(img_inp_path).shape\n",
    "\n",
    "    payload = {\n",
    "        \"prompt\": sd_params[\"prompt\"],\n",
    "        \"negative_prompt\": \"\",\n",
    "        \"styles\": [],\n",
    "        \"seed\": -1,\n",
    "        \"subseed\": -1,\n",
    "        \"subseed_strength\": 0,\n",
    "        \"seed_resize_from_h\": -1,\n",
    "        \"seed_resize_from_w\": -1,\n",
    "        \"sampler_name\": sd_params[\"sampler\"],\n",
    "        \"scheduler\": sd_params[\"scheduler\"],\n",
    "        \"batch_size\": 1,\n",
    "        \"n_iter\": 1,\n",
    "        \"steps\": sd_params[\"steps\"],\n",
    "        \"cfg_scale\": sd_params[\"cfg\"],\n",
    "        \"distilled_cfg_scale\": 3.5,\n",
    "        \"width\": img_w,\n",
    "        \"height\": img_h,\n",
    "        \"restore_faces\": False,\n",
    "        \"tiling\": False,\n",
    "        \"do_not_save_samples\": False,\n",
    "        \"do_not_save_grid\": False,\n",
    "        \"eta\": 0,\n",
    "        \"denoising_strength\": sd_params[\"denoising\"],\n",
    "        \"s_min_uncond\": 0.0,\n",
    "        \"s_churn\": 0.0,\n",
    "        \"s_tmax\": None,\n",
    "        \"s_tmin\": 0.0,\n",
    "        \"s_noise\": 1.0,\n",
    "        \"override_settings\": {\"sd_model_checkpoint\": sd_params[\"model\"], \"CLIP_stop_at_last_layers\": 1},\n",
    "        \"override_settings_restore_afterwards\": False,\n",
    "        # \"refiner_checkpoint\": \"string\",\n",
    "        \"refiner_switch_at\": 0,\n",
    "        \"disable_extra_networks\": False,\n",
    "        # \"firstpass_image\": \"string\",\n",
    "        \"comments\": {},\n",
    "        \"init_images\": [img_inp_base64],\n",
    "        \"resize_mode\": 0,\n",
    "        \"image_cfg_scale\": 1.5,\n",
    "        \"mask\": img_msk_base64,\n",
    "        \"mask_blur_x\": 4,\n",
    "        \"mask_blur_y\": 4,\n",
    "        \"mask_blur\": 4,\n",
    "        \"mask_round\": True,\n",
    "        \"inpainting_fill\": 1,\n",
    "        \"inpaint_full_res\": 0,\n",
    "        \"inpaint_full_res_padding\": 32,\n",
    "        \"inpainting_mask_invert\": 0,\n",
    "        \"initial_noise_multiplier\": 1.0,\n",
    "        # \"latent_mask\": \"string\",\n",
    "        # \"force_task_id\": \"string\",\n",
    "        \"hr_distilled_cfg\": 3.5,\n",
    "        \"sampler_index\": \"Euler\",\n",
    "        \"include_init_images\": False,\n",
    "        \"script_name\": None,\n",
    "        \"script_args\": [],\n",
    "        \"send_images\": True,\n",
    "        \"save_images\": False,\n",
    "        \"alwayson_scripts\": {},\n",
    "        # \"infotext\": \"string\"\n",
    "    }\n",
    "\n",
    "    def request_forge_instance(payload, savepath):\n",
    "        try:\n",
    "            with requests.post(url=FORGE_INSTANCE_URL+\"/sdapi/v1/img2img\", json=payload) as req:\n",
    "                with open(savepath, \"wb\") as f:\n",
    "                    f.write(base64.b64decode(req.json()[\"images\"][0]))\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error: {e}\")\n",
    "            print(f\"⚠️ req.json(): {req.json()}\")\n",
    "    request_forge_instance(payload, img_out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de7162be",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_INPUT     = \"_test/img_0.jpg\" # r\"D:\\DRIVE\\Drive\\ig_xouuuus\\IG_Girls_Photos\\xouuuus\\3.jpg\" # \"_test/img_0.jpg\"\n",
    "PATH_UPSCALED  = \"_output/1_upscaled.jpg\"\n",
    "PATH_KEYPOINTS = \"_output/2_keypoints.jpg\"\n",
    "PATH_FACEMASK  = \"_output/2_facemask.jpg\"\n",
    "GENERATION_VARIANTS = [\n",
    "    {\n",
    "        \"WIDTH\": 1080,\n",
    "        \"PATH_UPSCALED_RESIZED\": \"_output/3_resized_1080.jpg\",\n",
    "        \"PATH_FACEMASK_RESIZED\": \"_output/3_facemask_1080.jpg\",\n",
    "        \"PATH_OUTPUT\": \"_output/4_output_1080.jpg\",\n",
    "        \"SD_PARAMS\": {\n",
    "            \"prompt\": \"best quality, masterpiece, ultra high res, photorealistic, 1girl, <lora:LORA_KoreaDL:0.5>\",\n",
    "            \"cfg\": 5, \"denoising\": 0.6, \"steps\": 20, \"sampler\": \"Euler a\", \"scheduler\": \"Automatic\", \"model\": \"MJX_V07\",\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"WIDTH\": 960,\n",
    "        \"PATH_UPSCALED_RESIZED\": \"_output/3_resized_960.jpg\",\n",
    "        \"PATH_FACEMASK_RESIZED\": \"_output/3_facemask_960.jpg\",\n",
    "        \"PATH_OUTPUT\": \"_output/4_output_960.jpg\",\n",
    "        \"SD_PARAMS\": {\n",
    "            \"prompt\": \"best quality, masterpiece, ultra high res, photorealistic, 1girl, <lora:LORA_KoreaDL:0.5>\",\n",
    "            \"cfg\": 5, \"denoising\": 0.6, \"steps\": 20, \"sampler\": \"Euler a\", \"scheduler\": \"Automatic\", \"model\": \"MJX_V07\",\n",
    "        }\n",
    "    },\n",
    "]\n",
    "\n",
    "# ----- 0\n",
    "shutil.copy2(PATH_INPUT, f\"_output/0_input{os.path.splitext(PATH_INPUT)[1]}\")\n",
    "# ----- 1\n",
    "upscale_image(PATH_INPUT, PATH_UPSCALED)\n",
    "# ----- 2\n",
    "create_facemask(PATH_UPSCALED, PATH_KEYPOINTS, PATH_FACEMASK, expand_scale_factor=1.4)\n",
    "# ----- 3\n",
    "for variant in GENERATION_VARIANTS:\n",
    "    resize_image(PATH_UPSCALED, variant[\"PATH_UPSCALED_RESIZED\"], new_width=variant[\"WIDTH\"])\n",
    "    resize_image(PATH_FACEMASK, variant[\"PATH_FACEMASK_RESIZED\"], new_width=variant[\"WIDTH\"])\n",
    "# ----- 4\n",
    "for variant in GENERATION_VARIANTS:\n",
    "    inpaint_image(variant[\"PATH_UPSCALED_RESIZED\"], variant[\"PATH_FACEMASK_RESIZED\"], variant[\"PATH_OUTPUT\"], variant[\"SD_PARAMS\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
