{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c245fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import base64\n",
    "import requests\n",
    "import numpy as np\n",
    "from deepface import DeepFace\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "\n",
    "FORGE_INSTANCE_URL = \"https://hfs1s0vb3480kc-1234.proxy.runpod.net\" # \"http://127.0.0.1:1234\" / \"https://*-1234.proxy.runpod.net\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b9bcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files(dir_path):\n",
    "    return [dir_path+os.path.relpath(os.path.join(root, f), dir_path) for root, _, files in os.walk(dir_path) for f in files]\n",
    "\n",
    "def upscale_image(img_inp_path, img_out_path):\n",
    "\n",
    "    with open(img_inp_path, \"rb\") as f_img_inp:\n",
    "        img_inp_base64 = base64.b64encode(f_img_inp.read()).decode('utf-8')\n",
    "    # img_h, img_w, _ = cv2.imread(img_inp_path).shape\n",
    "\n",
    "    payload = {\n",
    "        \"resize_mode\": 0,                  # Sets the resize mode: 0 to upscale by upscaling_resize amount, 1 to upscale up to upscaling_resize_h x upscaling_resize_w.\n",
    "        \"show_extras_results\": False,      # Should the backend return the generated image?\n",
    "        \"gfpgan_visibility\": 0.35,         # Sets the visibility of GFPGAN, values should be between 0 and 1.\n",
    "        \"codeformer_visibility\": 0,        # Sets the visibility of CodeFormer, values should be between 0 and 1.\n",
    "        \"codeformer_weight\": 0,            # Sets the weight of CodeFormer, values should be between 0 and 1.\n",
    "        \"upscaling_resize\": 4,             # By how much to upscale the image, only used when resize_mode=0.\n",
    "        \"upscaling_resize_w\": 512,         # Target width for the upscaler to hit. Only used when resize_mode=1.\n",
    "        \"upscaling_resize_h\": 512,         # Target height for the upscaler to hit. Only used when resize_mode=1.\n",
    "        \"upscaling_crop\": True,            # Should the upscaler crop the image to fit in the chosen size?\n",
    "        \"upscaler_1\": \"R-ESRGAN 4x+\",      # The name of the main upscaler to use\n",
    "        \"upscaler_2\": \"None\",              # The name of the secondary upscaler to use\n",
    "        \"extras_upscaler_2_visibility\": 0, # Sets the visibility of secondary upscaler, values should be between 0 and 1.\n",
    "        \"upscale_first\": False,            # Should the upscaler run before restoring faces?\n",
    "        \"image\": img_inp_base64            # Image to work on, must be a Base64 string containing the image's data.\n",
    "    }\n",
    "\n",
    "    def request_forge_instance(payload, img_out_path):\n",
    "        try:\n",
    "            with requests.post(url=FORGE_INSTANCE_URL+\"/sdapi/v1/extra-single-image\", json=payload) as req:\n",
    "                with open(img_out_path, \"wb\") as f:\n",
    "                    f.write(base64.b64decode(req.json()[\"image\"]))\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error: {e}\")\n",
    "            print(f\"⚠️ req.json(): {req.json()}\")\n",
    "    request_forge_instance(payload, img_out_path)\n",
    "\n",
    "def resize_image(img_inp_path, img_out_path, new_width=1080):\n",
    "    img = cv2.imread(img_inp_path)\n",
    "    h, w, _ = img.shape\n",
    "    new_height = int(h * new_width / w)\n",
    "    img_resized = cv2.resize(img, (new_width, new_height), interpolation=cv2.INTER_LANCZOS4)\n",
    "    cv2.imwrite(img_out_path, img_resized)\n",
    "\n",
    "def create_facemask(img_inp_path, img_keypoints_path, img_mask_path, expand_scale_factor=1.2):\n",
    "    def get_ls_keypoints(img_inp_path, img_out_path, expand_scale_factor):\n",
    "        def expand_polygon(ls_keypoints, expand_scale_factor):\n",
    "            points = np.array(ls_keypoints, dtype=np.float32)                      # Convert keypoints to a NumPy array\n",
    "            centroid = np.mean(points, axis=0)                                     # Calculate the centroid of the polygon\n",
    "            expanded_points = centroid + (points - centroid) * expand_scale_factor # Translate points to origin (subtract centroid), scale, and translate back\n",
    "            expanded_points = expanded_points.astype(np.int32)                     # Convert back to integer coordinates for OpenCV\n",
    "            return expanded_points.tolist()\n",
    "        # -----\n",
    "        face_objs = []\n",
    "        try:\n",
    "            face_objs = DeepFace.extract_faces(img_inp_path, detector_backend='retinaface', align=True)\n",
    "        except:\n",
    "            pass\n",
    "        # -----\n",
    "        ls_keypoints = []\n",
    "        for fce in face_objs:\n",
    "            x,y,w,h = fce[\"facial_area\"][\"x\"], fce[\"facial_area\"][\"y\"], fce[\"facial_area\"][\"w\"], fce[\"facial_area\"][\"h\"]\n",
    "            ls_keypoints.append([(x,y), (x,y+h), (x+w,y+h), (x+w,y)])\n",
    "        ls_keypoints_expanded = [expand_polygon(e, expand_scale_factor) for e in ls_keypoints]\n",
    "        # ----- Draw keypoints -----\n",
    "        img = cv2.imread(img_inp_path)\n",
    "        for i in range(len(ls_keypoints)):\n",
    "            DRAW_THICKNESS = int(img.shape[1]/100)\n",
    "            cv2.polylines(img, [np.array(ls_keypoints[i], dtype=np.int32)], isClosed=True, color=(0, 0, 255), thickness=DRAW_THICKNESS)\n",
    "            cv2.polylines(img, [np.array(ls_keypoints_expanded[i], dtype=np.int32)], isClosed=True, color=(0, 255, 0), thickness=DRAW_THICKNESS)\n",
    "        cv2.imwrite(img_out_path, img)\n",
    "        # ----- ---- -----\n",
    "        return ls_keypoints_expanded\n",
    "\n",
    "    ls_keypoints = get_ls_keypoints(img_inp_path, img_keypoints_path, expand_scale_factor)\n",
    "    h, w, _ = cv2.imread(img_inp_path).shape\n",
    "\n",
    "    # ----- Create mask image ----\n",
    "    img_mask = np.full((h, w, 3), 255, dtype=np.uint8) # Create a white mask (Default to inpaint all)\n",
    "    if len(ls_keypoints) == 0:\n",
    "        print(f\"⚠️ > {img_inp_path} > No face detected\")\n",
    "    elif len(ls_keypoints) == 1:\n",
    "        img_mask = np.full((h, w, 3), 0, dtype=np.uint8) # Create a black mask\n",
    "        face_polygon = np.array(ls_keypoints[0], np.int32).reshape((-1, 1, 2))\n",
    "        cv2.fillPoly(img_mask, [face_polygon], (255, 255, 255)) # Fill the face polygon with white\n",
    "    elif len(ls_keypoints) > 1:\n",
    "        print(f\"⚠️ > {img_inp_path} > Many faces detected\")\n",
    "    cv2.imwrite(img_mask_path, img_mask)\n",
    "\n",
    "def sd_img2img(img_inp_path, img_msk_path=None, img_out_path=\"output/_test.jpg\"):\n",
    "\n",
    "    img_inp_base64 = None\n",
    "    img_msk_base64 = None\n",
    "    if img_inp_path:\n",
    "        with open(img_inp_path, \"rb\") as f:\n",
    "            img_inp_base64 = base64.b64encode(f.read()).decode('utf-8')\n",
    "    if img_msk_path:\n",
    "        with open(img_msk_path, \"rb\") as f:\n",
    "            img_msk_base64 = base64.b64encode(f.read()).decode('utf-8')\n",
    "    img_h, img_w, _ = cv2.imread(img_inp_path).shape\n",
    "\n",
    "    sd_params = {\n",
    "        \"prompt\": \"masterpiece, best quality, 1girl, artist: bacun\",\n",
    "        \"negative\": \"bad quality, worst quality, worst detail, artist name, text, signature, logo, watermark\",\n",
    "        \"width\": img_w,\n",
    "        \"height\": img_h,\n",
    "        \"model\": \"WAI_V11\",\n",
    "        # \"model\": \"MJX_V07\",\n",
    "        \"steps\": 20,\n",
    "        \"cfg\": 5,\n",
    "        \"denoising\": 0.5,\n",
    "    }\n",
    "\n",
    "    payload = {\n",
    "        \"prompt\": sd_params[\"prompt\"],\n",
    "        \"negative_prompt\": sd_params[\"negative\"],\n",
    "        \"styles\": [],\n",
    "        \"seed\": -1,\n",
    "        \"subseed\": -1,\n",
    "        \"subseed_strength\": 0,\n",
    "        \"seed_resize_from_h\": -1,\n",
    "        \"seed_resize_from_w\": -1,\n",
    "        \"sampler_name\": \"Euler a\",\n",
    "        \"scheduler\": \"Karras\",\n",
    "        \"batch_size\": 1,\n",
    "        \"n_iter\": 1,\n",
    "        \"steps\": sd_params[\"steps\"],\n",
    "        \"cfg_scale\": sd_params[\"cfg\"],\n",
    "        \"distilled_cfg_scale\": 3.5,\n",
    "        \"width\": sd_params[\"width\"],\n",
    "        \"height\": sd_params[\"height\"],\n",
    "        \"restore_faces\": False,\n",
    "        \"tiling\": False,\n",
    "        \"do_not_save_samples\": False,\n",
    "        \"do_not_save_grid\": False,\n",
    "        \"eta\": 0,\n",
    "        \"denoising_strength\": sd_params[\"denoising\"],\n",
    "        \"s_min_uncond\": 0.0,\n",
    "        \"s_churn\": 0.0,\n",
    "        \"s_tmax\": None,\n",
    "        \"s_tmin\": 0.0,\n",
    "        \"s_noise\": 1.0,\n",
    "        \"override_settings\": {\"sd_model_checkpoint\": sd_params[\"model\"], \"CLIP_stop_at_last_layers\": 1},\n",
    "        \"override_settings_restore_afterwards\": False,\n",
    "        # \"refiner_checkpoint\": \"string\",\n",
    "        \"refiner_switch_at\": 0,\n",
    "        \"disable_extra_networks\": False,\n",
    "        # \"firstpass_image\": \"string\",\n",
    "        \"comments\": {},\n",
    "        \"init_images\": [img_inp_base64],\n",
    "        \"resize_mode\": 1,\n",
    "        \"image_cfg_scale\": 1.5,\n",
    "        \"mask\": img_msk_base64,\n",
    "        \"mask_blur_x\": 4,\n",
    "        \"mask_blur_y\": 4,\n",
    "        \"mask_blur\": 4,\n",
    "        \"mask_round\": True,\n",
    "        \"inpainting_fill\": 1,\n",
    "        \"inpaint_full_res\": 0,\n",
    "        \"inpaint_full_res_padding\": 32,\n",
    "        \"inpainting_mask_invert\": 0,\n",
    "        \"initial_noise_multiplier\": 1.0,\n",
    "        # \"latent_mask\": \"string\",\n",
    "        # \"force_task_id\": \"string\",\n",
    "        \"hr_distilled_cfg\": 3.5,\n",
    "        \"sampler_index\": \"Euler\",\n",
    "        \"include_init_images\": False,\n",
    "        \"script_name\": None,\n",
    "        \"script_args\": [],\n",
    "        \"send_images\": True,\n",
    "        \"save_images\": False,\n",
    "        \"alwayson_scripts\": {},\n",
    "        # \"infotext\": \"string\"\n",
    "    }\n",
    "\n",
    "    def request_forge_instance(payload, savepath):\n",
    "        try:\n",
    "            with requests.post(url=FORGE_INSTANCE_URL+\"/sdapi/v1/img2img\", json=payload) as req:\n",
    "                with open(savepath, \"wb\") as f:\n",
    "                    f.write(base64.b64decode(req.json()[\"images\"][0]))\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error: {e}\")\n",
    "            print(f\"⚠️ req.json(): {req.json()}\")\n",
    "\n",
    "    request_forge_instance(payload, img_out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352ef760",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_PATHS_INPUT = list_files(\"input/\")\n",
    "for img_inp_path in ALL_PATHS_INPUT:\n",
    "    try:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        PATH_INPUT = img_inp_path\n",
    "        OUTPUT_DIR_NAME = os.path.splitext(os.path.basename(PATH_INPUT))[0] # \"path/input/img_0.jpg\" -> \"img_0\"\n",
    "        os.makedirs(f\"output/{OUTPUT_DIR_NAME}\", exist_ok=True)\n",
    "        PATH_UPSCALED   = f\"output/{OUTPUT_DIR_NAME}/1_upscaled.jpg\"\n",
    "        PATH_KEYPOINTS  = f\"output/{OUTPUT_DIR_NAME}/2_keypoints.jpg\"\n",
    "        PATH_FACEMASK   = f\"output/{OUTPUT_DIR_NAME}/2_facemask.jpg\"\n",
    "        PATH_UPSCALED_RESIZED = f\"output/{OUTPUT_DIR_NAME}/3_resized.jpg\",\n",
    "        PATH_FACEMASK_RESIZED = f\"output/{OUTPUT_DIR_NAME}/3_facemask.jpg\",\n",
    "        PATH_OUTPUT =           f\"output/{OUTPUT_DIR_NAME}_4_output_00001.jpg\",\n",
    "\n",
    "        shutil.copy2(PATH_INPUT, f\"output/{OUTPUT_DIR_NAME}/0_input{os.path.splitext(PATH_INPUT)[1]}\")\n",
    "        upscale_image(PATH_INPUT, PATH_UPSCALED)\n",
    "        create_facemask(PATH_UPSCALED, PATH_KEYPOINTS, PATH_FACEMASK, expand_scale_factor=1.5)\n",
    "        resize_image(PATH_UPSCALED, PATH_UPSCALED_RESIZED, new_width=1080)\n",
    "        resize_image(PATH_FACEMASK, PATH_FACEMASK_RESIZED, new_width=1080)\n",
    "        sd_img2img(PATH_UPSCALED_RESIZED, PATH_FACEMASK_RESIZED, PATH_OUTPUT)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    except Exception as er:\n",
    "        os.makedirs(\"input_failed\", exist_ok=True)\n",
    "        shutil.copy2(img_inp_path, \"input_failed/\")\n",
    "        print(f\"⚠️ > {img_inp_path} > Error: {er}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
