{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f53b4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "FORGE_INSTANCE_URL = \"https://v0yf0nginj87vx-1234.proxy.runpod.net\" # \"http://127.0.0.1:1234\" / \"https://*-1234.proxy.runpod.net\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469911f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import requests\n",
    "import base64\n",
    "import json\n",
    "import time\n",
    "import cv2\n",
    "import os\n",
    "os.makedirs(\"_input\", exist_ok=True)\n",
    "os.makedirs(\"_output\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6137d96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imagen_upscale(img_inp_path, img_out_path, scale_factor=4, upscaler=\"R-ESRGAN 4x+\"):\n",
    "    # ----- UPSCALE -----\n",
    "    # R-ESRGAN 4x+ / R-ESRGAN 4x+ Anime6B\n",
    "    # -------------------\n",
    "    print(f\"UPSCALE > {img_inp_path} > {upscaler} > x{scale_factor}\")\n",
    "\n",
    "    with open(img_inp_path, \"rb\") as f_img_inp:\n",
    "        img_inp_base64 = base64.b64encode(f_img_inp.read()).decode('utf-8')\n",
    "    # img_h, img_w, _ = cv2.imread(img_inp_path).shape\n",
    "\n",
    "    payload = {\n",
    "        \"resize_mode\": 0,                         # Sets the resize mode: 0 to upscale by upscaling_resize amount, 1 to upscale up to upscaling_resize_h x upscaling_resize_w.\n",
    "        \"show_extras_results\": False,             # Should the backend return the generated image?\n",
    "        \"gfpgan_visibility\": 0.35,                # Sets the visibility of GFPGAN, values should be between 0 and 1.\n",
    "        \"codeformer_visibility\": 0,               # Sets the visibility of CodeFormer, values should be between 0 and 1.\n",
    "        \"codeformer_weight\": 0,                   # Sets the weight of CodeFormer, values should be between 0 and 1.\n",
    "        \"upscaling_resize\": scale_factor,         # By how much to upscale the image, only used when resize_mode=0.\n",
    "        \"upscaling_resize_w\": 512,                # Target width for the upscaler to hit. Only used when resize_mode=1.\n",
    "        \"upscaling_resize_h\": 512,                # Target height for the upscaler to hit. Only used when resize_mode=1.\n",
    "        \"upscaling_crop\": True,                   # Should the upscaler crop the image to fit in the chosen size?\n",
    "        \"upscaler_1\": upscaler,                   # The name of the main upscaler to use\n",
    "        \"upscaler_2\": \"None\",                     # The name of the secondary upscaler to use\n",
    "        \"extras_upscaler_2_visibility\": 0,        # Sets the visibility of secondary upscaler, values should be between 0 and 1.\n",
    "        \"upscale_first\": False,                   # Should the upscaler run before restoring faces?\n",
    "        \"image\": img_inp_base64                   # Image to work on, must be a Base64 string containing the image's data.\n",
    "    }\n",
    "\n",
    "    def request_forge_instance(payload, img_out_path):\n",
    "        try:\n",
    "            with requests.post(url=FORGE_INSTANCE_URL+\"/sdapi/v1/extra-single-image\", json=payload) as req:\n",
    "                with open(img_out_path, \"wb\") as f:\n",
    "                    f.write(base64.b64decode(req.json()[\"image\"]))\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ imagen_upscale (x{scale_factor}) > Error: {e}\")\n",
    "            print(f\"⚠️ imagen_upscale (x{scale_factor}) > req.json(): {req.json()}\")\n",
    "    request_forge_instance(payload, img_out_path)\n",
    "\n",
    "def imagen_img2img(img_inp_path, img_msk_path=None, img_out_path=\"_output/_test.jpg\", sd_params={}):\n",
    "    # ----- IMG2IMG -----\n",
    "    # 1. Mask -> Inpaint mask area\n",
    "    # 2. No mask -> Inpaint the whole image\n",
    "    # -------------------\n",
    "    # sd_params = {\n",
    "    #     \"model\": \"WAI_V11\",\n",
    "    #     \"prompt\": f\"masterpiece, best quality, <PROMPT>\",\n",
    "    #     \"negative\": \"bad quality, worst quality, worst detail\",\n",
    "    #     \"sampler\": \"Euler a\",\n",
    "    #     \"scheduler\": \"Karras\",\n",
    "    #     \"steps\": 20,\n",
    "    #     \"cfg\": 6.0,\n",
    "    #     \"denoising\": 0.6,\n",
    "    #     \"seed\": -1,\n",
    "    # }\n",
    "    # -------------------\n",
    "    print(f\"IMG2IMG > {img_inp_path} > {sd_params}\")\n",
    "    \n",
    "    img_inp_base64 = None\n",
    "    img_msk_base64 = None\n",
    "    if img_inp_path:\n",
    "        with open(img_inp_path, \"rb\") as f:\n",
    "            img_inp_base64 = base64.b64encode(f.read()).decode('utf-8')\n",
    "    if img_msk_path:\n",
    "        with open(img_msk_path, \"rb\") as f:\n",
    "            img_msk_base64 = base64.b64encode(f.read()).decode('utf-8')\n",
    "    img_h, img_w, _ = cv2.imread(img_inp_path).shape\n",
    "\n",
    "    payload = {\n",
    "        \"prompt\": sd_params[\"prompt\"],\n",
    "        \"negative_prompt\": sd_params[\"negative\"],\n",
    "        \"styles\": [],\n",
    "        \"seed\": sd_params[\"seed\"],\n",
    "        \"subseed\": -1,\n",
    "        \"subseed_strength\": 0,\n",
    "        \"seed_resize_from_h\": -1,\n",
    "        \"seed_resize_from_w\": -1,\n",
    "        \"sampler_name\": sd_params[\"sampler\"],\n",
    "        \"scheduler\": sd_params[\"scheduler\"],\n",
    "        \"batch_size\": 1,\n",
    "        \"n_iter\": 1,\n",
    "        \"steps\": sd_params[\"steps\"],\n",
    "        \"cfg_scale\": sd_params[\"cfg\"],\n",
    "        \"distilled_cfg_scale\": 3.5,\n",
    "        \"width\": img_w,\n",
    "        \"height\": img_h,\n",
    "        \"restore_faces\": False,\n",
    "        \"tiling\": False,\n",
    "        \"do_not_save_samples\": False,\n",
    "        \"do_not_save_grid\": False,\n",
    "        \"eta\": 0,\n",
    "        \"denoising_strength\": sd_params[\"denoising\"],\n",
    "        \"s_min_uncond\": 0.0,\n",
    "        \"s_churn\": 0.0,\n",
    "        \"s_tmax\": None,\n",
    "        \"s_tmin\": 0.0,\n",
    "        \"s_noise\": 1.0,\n",
    "        \"override_settings\": {\"sd_model_checkpoint\": sd_params[\"model\"], \"CLIP_stop_at_last_layers\": 1},\n",
    "        \"override_settings_restore_afterwards\": False,\n",
    "        # \"refiner_checkpoint\": \"string\",\n",
    "        \"refiner_switch_at\": 0,\n",
    "        \"disable_extra_networks\": False,\n",
    "        # \"firstpass_image\": \"string\",\n",
    "        \"comments\": {},\n",
    "        \"init_images\": [img_inp_base64],\n",
    "        \"resize_mode\": 1,\n",
    "        \"image_cfg_scale\": 1.5,\n",
    "        \"mask\": img_msk_base64,\n",
    "        \"mask_blur_x\": 4,\n",
    "        \"mask_blur_y\": 4,\n",
    "        \"mask_blur\": 4,\n",
    "        \"mask_round\": True,\n",
    "        \"inpainting_fill\": 1,\n",
    "        \"inpaint_full_res\": 0,\n",
    "        \"inpaint_full_res_padding\": 32,\n",
    "        \"inpainting_mask_invert\": 0,\n",
    "        \"initial_noise_multiplier\": 1.0,\n",
    "        # \"latent_mask\": \"string\",\n",
    "        # \"force_task_id\": \"string\",\n",
    "        \"hr_distilled_cfg\": 3.5,\n",
    "        \"sampler_index\": \"Euler\",\n",
    "        \"include_init_images\": False,\n",
    "        \"script_name\": None,\n",
    "        \"script_args\": [],\n",
    "        \"send_images\": True,\n",
    "        \"save_images\": False,\n",
    "        \"alwayson_scripts\": {},\n",
    "        # \"infotext\": \"string\"\n",
    "    }\n",
    "\n",
    "    def request_forge_instance(payload, savepath):\n",
    "        try:\n",
    "            with requests.post(url=FORGE_INSTANCE_URL+\"/sdapi/v1/img2img\", json=payload) as req:\n",
    "                \n",
    "                # Optional - Add seed info to filename\n",
    "                actual_seed = json.loads(req.json()[\"info\"])[\"seed\"]\n",
    "                savepath = savepath.replace(\".jpg\", f\" ({actual_seed}).jpg\")\n",
    "\n",
    "                with open(savepath, \"wb\") as f:\n",
    "                    f.write(base64.b64decode(req.json()[\"images\"][0]))\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ imagen_img2img > Error: {e}\")\n",
    "            print(f\"⚠️ imagen_img2img > req.json(): {req.json()}\")\n",
    "    request_forge_instance(payload, img_out_path)\n",
    "\n",
    "# # Test both imagen_img2img and imagen_upscale\n",
    "# SD_PARAMS = {\n",
    "#     \"model\": \"WAI_V11\",\n",
    "#     \"prompt\": f\"masterpiece, best quality, artist: wamudraws\",\n",
    "#     \"negative\": \"bad quality, worst quality, worst detail\",\n",
    "#     \"sampler\": \"Euler a\",\n",
    "#     \"scheduler\": \"Karras\",\n",
    "#     \"steps\": 20,\n",
    "#     \"cfg\": 6.0,\n",
    "#     \"denoising\": 0.6,\n",
    "#     \"seed\": -1,\n",
    "# }\n",
    "# img_inp_path = \"_input/_test.jpg\"\n",
    "# imagen_img2img(img_inp_path, img_msk_path=None, img_out_path=\"_output/_test_img2img.jpg\", sd_params=SD_PARAMS)\n",
    "# imagen_upscale(img_inp_path, img_out_path=\"_output/_test_upscale.jpg\", scale_factor=4, upscaler=\"R-ESRGAN 4x+ Anime6B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20fd438",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imagen_facemask(img_inp_path, img_keypoints_path, img_mask_path, expand_scale_factor=1.5):\n",
    "    # -------------------- Helpers --------------------\n",
    "    def helper_expand_polygon(ls_keypoints, expand_scale_factor):\n",
    "        points = np.array(ls_keypoints, dtype=np.float32)                      # Convert keypoints to a NumPy array\n",
    "        centroid = np.mean(points, axis=0)                                     # Calculate the centroid of the polygon\n",
    "        expanded_points = centroid + (points - centroid) * expand_scale_factor # Translate points to origin (subtract centroid), scale, and translate back\n",
    "        expanded_points = expanded_points.astype(np.int32)                     # Convert back to integer coordinates for OpenCV\n",
    "        return expanded_points.tolist()\n",
    "    def helper_create_mask_image(img_inp_path, img_mask_path, ls_keypoints):\n",
    "        h, w, _ = cv2.imread(img_inp_path).shape\n",
    "        img_mask = np.full((h, w, 3), 255, dtype=np.uint8) # Create a white mask (Default to inpaint all)\n",
    "        if len(ls_keypoints) == 0:\n",
    "            print(f\"⚠️ imagen_facemask > {img_inp_path} > No face detected\")\n",
    "        elif len(ls_keypoints) == 1:\n",
    "            img_mask = np.full((h, w, 3), 0, dtype=np.uint8) # Create a black mask\n",
    "            cv2.fillPoly(img_mask, [np.array(ls_keypoints[0], np.int32)], (255, 255, 255)) # Fill the face polygon with white\n",
    "        elif len(ls_keypoints) > 1:\n",
    "            print(f\"⚠️ imagen_facemask > {img_inp_path} > Many faces detected\")\n",
    "        cv2.imwrite(img_mask_path, img_mask)\n",
    "    def helper_draw_keypoints(img_inp_path, img_keypoints_path, ls_keypoints, ls_keypoints_expanded):\n",
    "        img = cv2.imread(img_inp_path)\n",
    "        LINE_THICKNESS = int(img.shape[1]/200)\n",
    "        POINT_THICKNESS = int(img.shape[1]/150)\n",
    "        for i in range(len(ls_keypoints)):\n",
    "            cv2.polylines(img, [np.array(ls_keypoints[i], dtype=np.int32)], isClosed=True, color=(0, 0, 255), thickness=LINE_THICKNESS)\n",
    "            cv2.polylines(img, [np.array(ls_keypoints_expanded[i], dtype=np.int32)], isClosed=True, color=(0, 255, 0), thickness=LINE_THICKNESS)\n",
    "        for ls_kps in ls_keypoints:\n",
    "            for (x, y) in ls_kps:\n",
    "                cv2.circle(img, (x, y), radius=POINT_THICKNESS, color=(0, 255, 0), thickness=-1)\n",
    "        cv2.imwrite(img_keypoints_path, img)\n",
    "    # -------------------- Extract ls_keypoints --------------------\n",
    "    def get_ls_keypoints_mediapipe(img_inp_path):\n",
    "        import mediapipe as mp\n",
    "        ls_keypoints = []\n",
    "        try:\n",
    "            MEDIAPIPE_FACE_OUTLINE_IDXS = [10,338,297,332,284,251,389,356,454,323,361,288,397,365,379,378,400,377,152,148,176,149,150,136,172,58,132,93,234,127,162,21,54,103,67,109]\n",
    "            img = cv2.imread(img_inp_path)\n",
    "            with mp.solutions.face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, refine_landmarks=True) as face_mesh:\n",
    "                results = face_mesh.process(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "                if results.multi_face_landmarks:\n",
    "                    for facelandmarks in results.multi_face_landmarks:\n",
    "                        h, w, _ = img.shape\n",
    "                        ls_kps = [(int(facelandmarks.landmark[idx].x*w), int(facelandmarks.landmark[idx].y*h)) for idx in MEDIAPIPE_FACE_OUTLINE_IDXS]\n",
    "                        ls_keypoints.append(ls_kps)\n",
    "        except Exception as er:\n",
    "            print(f\"⚠️ Error > {er}\")\n",
    "        return ls_keypoints\n",
    "    def get_ls_keypoints_deepface(img_inp_path):\n",
    "        from deepface import DeepFace\n",
    "        ls_keypoints = []\n",
    "        try:\n",
    "            face_objs = []\n",
    "            try: face_objs = DeepFace.extract_faces(img_inp_path, detector_backend='retinaface', align=True)\n",
    "            except: pass\n",
    "            for fce in face_objs:\n",
    "                x,y,w,h = fce[\"facial_area\"][\"x\"], fce[\"facial_area\"][\"y\"], fce[\"facial_area\"][\"w\"], fce[\"facial_area\"][\"h\"]\n",
    "                ls_keypoints.append([(x,y), (x,y+h), (x+w,y+h), (x+w,y)])\n",
    "        except Exception as er:\n",
    "            print(f\"⚠️ Error > {er}\")\n",
    "        return ls_keypoints\n",
    "    # -------------------- Main --------------------\n",
    "    ls_keypoints = get_ls_keypoints_mediapipe(img_inp_path)\n",
    "    if len(ls_keypoints) == 0:\n",
    "        ls_keypoints = get_ls_keypoints_deepface(img_inp_path)\n",
    "    ls_keypoints_expanded = [helper_expand_polygon(e, expand_scale_factor) for e in ls_keypoints]\n",
    "    helper_draw_keypoints(img_inp_path, img_keypoints_path, ls_keypoints, ls_keypoints_expanded)\n",
    "    helper_create_mask_image(img_inp_path, img_mask_path, ls_keypoints_expanded)\n",
    "\n",
    "# imagen_facemask(img_inp_path=\"_input/_test.jpg\", img_keypoints_path=\"_output/_test_facemask_kps.jpg\", img_mask_path=\"_output/_test_facemask.jpg\", expand_scale_factor=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f056f6",
   "metadata": {},
   "source": [
    "-----\n",
    "# Inference\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3736fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARTIST_TAGS = ['','akairiot','aogisa','bacun','chengongzi123','chihunhentai','ciloranko','donburi_(donburikazoku)','dramus','eigaka','eu03','ge-b','gogalking','haoni','horn/wood','hu_dako','hxd','inudori','jima','kidmo','kotorai','kyuuba_melo','linsun','love_cacao','menma_(enaic31)','milkychu','minaba_hideo','mochizuki_kei','nac000','noriuma','oastlv','pottsness','rariatto_(ganguri)','ratatatat74','sho_(sho_lwlw)','siu_(siu0207)','slugbox','starshadowmagician','tianliang_duohe_fangdongye','varniskarnis','wamudraws','zankuro']\n",
    "# ARTIST_TAGS = ['','aogisa','bacun','chengongzi123','ciloranko','donburi_(donburikazoku)','eigaka','eu03','ge-b','gogalking','haoni','inudori','jima','kidmo','kyuuba_melo','linsun','love_cacao','milkychu','minaba_hideo','mochizuki_kei','nac000','noriuma','oastlv','rariatto_(ganguri)','ratatatat74','sho_(sho_lwlw)','siu_(siu0207)','starshadowmagician','tianliang_duohe_fangdongye','varniskarnis','wamudraws','zankuro']\n",
    "# ARTIST_TAGS = ['chengongzi123', 'oastlv', 'ciloranko','tianliang_duohe_fangdongye','kyuuba_melo','starshadowmagician']\n",
    "# ARTIST_TAGS = ['chengongzi123','ciloranko','oastlv','tianliang_duohe_fangdongye']\n",
    "# ARTIST_TAGS = ['chengongzi123, ciloranko, oastlv, tianliang_duohe_fangdongye']\n",
    "# ARTIST_TAGS = ['chengongzi123, ciloranko, tianliang_duohe_fangdongye', 'ciloranko, tianliang_duohe_fangdongye, chengongzi123', 'tianliang_duohe_fangdongye, chengongzi123, ciloranko']\n",
    "\n",
    "for artist_tag in ARTIST_TAGS:\n",
    "    SD_PARAMS = {\n",
    "        \"model\": \"WAI_V11\",\n",
    "        \n",
    "        \n",
    "        \n",
    "        \"prompt\": f\"({artist_tag}:0.9), general, (1boy, portrait, looking_at_viewer:1.1), (masterpiece, best quality, amazing quality:0.5)\",\n",
    "        \n",
    "\n",
    "\n",
    "        \"negative\": \"bad quality, worst quality, worst detail\",\n",
    "        \"sampler\": \"Euler a\",\n",
    "        \"scheduler\": \"Karras\",\n",
    "        \"steps\": 20,\n",
    "        \"cfg\": 7.0,\n",
    "        \"denoising\": 1.0,\n",
    "\n",
    "        # \"seed\": -1,\n",
    "        # \"seed\": 1234567890,\n",
    "        # \"seed\": 9876543210,\n",
    "        # \"seed\": 2468135790,\n",
    "        # \"seed\": 1357924680,\n",
    "    }\n",
    "    img_inp_path = \"_input/1792x1024.jpg\"\n",
    "    img_out_path = \"_output/\" + SD_PARAMS[\"prompt\"].replace(\":\", \"\").replace(\"/\", \"\") + \" (\" + SD_PARAMS[\"model\"] + \")\" + \".jpg\"\n",
    "    # ----------\n",
    "    time_start = time.time()\n",
    "    try:\n",
    "        imagen_img2img(img_inp_path=img_inp_path, img_msk_path=None, img_out_path=img_out_path, sd_params=SD_PARAMS)\n",
    "    except Exception as er:\n",
    "        try:\n",
    "            imagen_img2img(img_inp_path=img_inp_path, img_msk_path=None, img_out_path=img_out_path, sd_params=SD_PARAMS)\n",
    "        except Exception as er:\n",
    "            print(f\"⚠️ Error: {er}\")\n",
    "    time_end = time.time()\n",
    "    print(f\"Execution time: {time_end - time_start:.1f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
